{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0983bcd3-929f-44f6-aace-5fa73295173c",
   "metadata": {},
   "source": [
    "# Felipe Cardona - Tarea 3 Clasificación De Datos Utilizando Imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0472892-9caf-46c8-a879-609a6da544f4",
   "metadata": {},
   "source": [
    "## Configurar e Importar dependencias necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66ecee12-68d3-4757-9ea1-69293ecfd9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.17.1 (from -r requirements.txt (line 1))\n",
      "  Using cached tensorflow-2.17.1-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting scikit-learn==1.5.2 (from -r requirements.txt (line 2))\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 5)) (3.8.4)\n",
      "Collecting tensorflow-intel==2.17.1 (from tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading tensorflow_intel-2.17.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn==1.5.2->-r requirements.txt (line 2)) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn==1.5.2->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn==1.5.2->-r requirements.txt (line 2)) (3.5.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (3.7.4.3)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2020.5)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (0.43.0)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading optree-0.13.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (2024.2.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1)) (2.1.5)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1->-r requirements.txt (line 1))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.17.1-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.9/11.0 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 22.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 20.2 MB/s eta 0:00:00\n",
      "Downloading tensorflow_intel-2.17.1-cp312-cp312-win_amd64.whl (382.4 MB)\n",
      "   ---------------------------------------- 0.0/382.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 13.4/382.4 MB 70.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 24.6/382.4 MB 60.0 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 28.6/382.4 MB 60.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 28.6/382.4 MB 60.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 28.6/382.4 MB 60.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 28.6/382.4 MB 60.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 42.7/382.4 MB 29.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 53.2/382.4 MB 31.7 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 63.7/382.4 MB 33.6 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 75.0/382.4 MB 36.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 84.4/382.4 MB 36.6 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 93.1/382.4 MB 36.9 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 102.2/382.4 MB 37.5 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 109.3/382.4 MB 37.3 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 121.4/382.4 MB 38.8 MB/s eta 0:00:07\n",
      "   ------------- ------------------------- 133.4/382.4 MB 39.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 146.3/382.4 MB 41.0 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 159.4/382.4 MB 42.3 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 170.9/382.4 MB 42.8 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 183.2/382.4 MB 43.7 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 194.8/382.4 MB 44.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 205.8/382.4 MB 44.6 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 217.8/382.4 MB 45.1 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 229.4/382.4 MB 45.5 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 240.6/382.4 MB 45.8 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 253.0/382.4 MB 46.2 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 265.6/382.4 MB 46.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 277.6/382.4 MB 46.4 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 290.2/382.4 MB 46.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 301.7/382.4 MB 52.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 313.5/382.4 MB 53.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 325.6/382.4 MB 54.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 337.6/382.4 MB 54.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 348.1/382.4 MB 54.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 360.4/382.4 MB 55.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  372.8/382.4 MB 56.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.2/382.4 MB 56.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.2/382.4 MB 56.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.2/382.4 MB 56.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.2/382.4 MB 56.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.2/382.4 MB 56.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.2/382.4 MB 56.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 382.4/382.4 MB 45.2 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 37.5 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 44.0 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 19.8 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 10.5/26.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.7/26.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 48.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 39.9 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 41.9 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-win_amd64.whl (283 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 20.1 MB/s eta 0:00:00\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, typing-extensions, tensorboard-data-server, pygments, protobuf, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, scikit-learn, optree, markdown-it-py, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.7.4\n",
      "    Uninstalling Pygments-2.7.4:\n",
      "      Successfully uninstalled Pygments-2.7.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.1\n",
      "    Uninstalling scikit-learn-1.5.1:\n",
      "      Successfully uninstalled scikit-learn-1.5.1\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 h5py-3.12.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.0 protobuf-4.25.5 pygments-2.18.0 rich-13.9.4 scikit-learn-1.5.2 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.1 tensorflow-intel-2.17.1 typing-extensions-4.12.2 werkzeug-3.1.1 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script pygmentize.exe is installed in 'C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6333f4b0-4407-4ba0-a7e8-9be5dc2cf45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531f3cf-e1e5-4b9a-b49f-f49fb3d1ec72",
   "metadata": {},
   "source": [
    "## Cargar las imagenes para entrenamiento\n",
    "\n",
    "Al momento de cargar nos encargaremos de eliminar todas aquellas imagenes corruptas que no sean posible de leer y tambien de normalizar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79bb8791-4cff-41be-b99f-f04d18e7de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = 'data/train'\n",
    "# Defino las dimensiones de las imágenes para estandarizar el procesamiento\n",
    "IMGSIZE = 100\n",
    "\n",
    "labelMapping = {\n",
    "    \"Shepherds Purse\": \"Shepherd’s Purse\",\n",
    "    # Agrega otros mapeos si es necesario\n",
    "}\n",
    "\n",
    "def loadImages(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(path):\n",
    "        # Obtener la etiqueta correcta usando el mapeo\n",
    "        label = labelMapping.get(folder, folder)  # Usa el nombre de la carpeta o el mapeo si existe\n",
    "        folderPath = os.path.join(path, folder)\n",
    "        # Procesar solo si es un directorio\n",
    "        if not os.path.isdir(folderPath):\n",
    "            continue\n",
    "        for file in glob.glob(os.path.join(folderPath, \"*.png\")):\n",
    "            img = cv2.imread(file)\n",
    "            if img is None:\n",
    "                print(f\"Error al cargar la imagen: {file}\")\n",
    "                continue\n",
    "            img = cv2.resize(img, (IMGSIZE, IMGSIZE))\n",
    "            img = img / 255.0  # Aplicamos normalización\n",
    "            images.append(img)\n",
    "            labels.append(label)  # Usar la etiqueta del mapeo en lugar del nombre de la carpeta\n",
    "    return np.array(images), np.array(labels)\n",
    "    \n",
    "X, y = loadImages(trainPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa0e037-cecb-4801-bf20-307f1d44bd01",
   "metadata": {},
   "source": [
    "### Pasaremos a codificar etiquetas y dividir los datos los datos en entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0794c9dc-ae64-425c-8f2a-bc99d95fd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "yEncoded = labelEncoder.fit_transform(y)\n",
    "yEncoded = to_categorical(yEncoded)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "Xtrain, Xval, yTrain, yVal = train_test_split(X, yEncoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8ed37-3cac-4fee-8619-efaf0c4a68ac",
   "metadata": {},
   "source": [
    "### Pasaremos a realizar ajustes y a entrenar el modelo de Regresión Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8df2c97f-6056-4e39-8e4a-e033fbd90aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Aplanar las imágenes\n",
    "xTrainFlat = Xtrain.reshape(Xtrain.shape[0], -1)\n",
    "xValFlat = Xval.reshape(Xval.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fede58e-9c7a-40e4-bbbd-ae13e55686e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logisticModel = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial')\n",
    "logisticModel.fit(xTrainFlat, yTrain.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917400e-8034-429d-81d0-7c95ce4053ea",
   "metadata": {},
   "source": [
    "### Realizando predicciones con los datos de entrenamiento consegumos los siguientes resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c190b80-bff9-4ccd-9cc1-45bc1316e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Logistic Regression): 0.5074626865671642\n",
      "Confusion Matrix (Logistic Regression):\n",
      " [[16  0  0  0  5 43  0  1  0  1]\n",
      " [ 0 49  5  3  1  0  0  7  5  6]\n",
      " [ 1  5 25  0  3  1  0  7  2  1]\n",
      " [ 1  1  1 58 12  0  9 22  7  6]\n",
      " [ 4  1  1  8 34 18  1  5  9  8]\n",
      " [12  0  2  3 11 88  0  1  3  6]\n",
      " [ 0  0  0 14  0  0 13 12  0  2]\n",
      " [ 3  2  4 14  6  3  4 36  1  5]\n",
      " [ 0 11  5  4  4  0  0  3 70  1]\n",
      " [ 3  0  2 10 14  7  0  9  4 19]]\n"
     ]
    }
   ],
   "source": [
    "yPred = logisticModel.predict(xValFlat)\n",
    "accuracy = accuracy_score(yVal.argmax(axis=1), yPred)\n",
    "confMatrix = confusion_matrix(yVal.argmax(axis=1), yPred)\n",
    "\n",
    "print(\"Accuracy (Logistic Regression):\", accuracy)\n",
    "print(\"Confusion Matrix (Logistic Regression):\\n\", confMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8adf2-7090-4db7-a4e1-e6bb95f0e8d7",
   "metadata": {},
   "source": [
    "### Ahora cargaremos las imagenes de test con el fin de poner a prueba la predicción del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab6af010-291a-4718-b8c2-a83af6ab14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPath = \"data/test\"\n",
    "\n",
    "# Función para cargar imágenes de prueba\n",
    "def loadTestImages(path):\n",
    "    testImages = []\n",
    "    filenames = []\n",
    "    filePaths = glob.glob(os.path.join(path, \"*.png\"))\n",
    "    for file in filePaths:\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.resize(img, (IMGSIZE, IMGSIZE))\n",
    "        img = img / 255.0\n",
    "        testImages.append(img)\n",
    "        filenames.append(os.path.basename(file))\n",
    "    return np.array(testImages), filenames\n",
    "\n",
    "Xtest, testFilenames = loadTestImages(testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f9c485b-3f8a-4e61-bd7f-50a6f4a1baaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0050ee5befb8db3ec3dc387a20f6f99a.png está en el dataset.\n"
     ]
    }
   ],
   "source": [
    "# Listar y ordenar alfabéticamente los archivos en el directorio de prueba\n",
    "test_filenames = sorted([f for f in os.listdir(testPath) if f.endswith(\".png\")])\n",
    "\n",
    "# Crear un DataFrame con los nombres de archivo ordenados alfabéticamente\n",
    "test_df = pd.DataFrame({\"file\": test_filenames})\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame para revisión\n",
    "test_df.head(10)\n",
    "\n",
    "file_to_check = \"0050ee5befb8db3ec3dc387a20f6f99a.png\"\n",
    "test_dir = \"data/test\"\n",
    "\n",
    "# Verifica si el archivo está en el directorio\n",
    "is_in_dataset = file_to_check in testFilenames\n",
    "\n",
    "# Imprime el resultado\n",
    "if is_in_dataset:\n",
    "    print(f\"{file_to_check} está en el dataset.\")\n",
    "else:\n",
    "    print(f\"{file_to_check} NO está en el dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d4c46-4a8a-43b8-9204-2a342eea6dc5",
   "metadata": {},
   "source": [
    "### Creamos la función que realice la predicción y genere el archivo para subir a Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b7a4a2b-9c37-429f-8528-41285e12366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para realizar predicciones y guardar el archivo CSV para Kaggle\n",
    "def predictAndSave(model, xTest, filenames, labelEncoder, outputFile=\"submission.csv\"):\n",
    "    predictions = model.predict(xTest)\n",
    "    if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "        predictedLabels = labelEncoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "    else:\n",
    "        predictedLabels = labelEncoder.inverse_transform(predictions)\n",
    "    df = pd.DataFrame({\"file\": filenames, \"label\": predictedLabels})\n",
    "    df.to_csv(outputFile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1120c-c5ed-4623-9a8e-7e840acf31c6",
   "metadata": {},
   "source": [
    "### Realizando predicción del modelo de Regresión Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "680d4762-5a27-4a8e-b154-1eedeb525c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtestFlat = Xtest.reshape(Xtest.shape[0], -1)\n",
    "predictAndSave(logisticModel, XtestFlat, testFilenames, labelEncoder, outputFile=\"logistic_regression.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
